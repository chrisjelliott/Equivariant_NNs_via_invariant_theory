{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN57JiGBLI3mBPUSh1hYKrJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisjelliott/Equivariant_NNs_via_invariant_theory/blob/main/Equivariant_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Equivariant Neural Networks for General Representations**\n",
        "\n",
        "In this notebook I'm going to implement some neural network models based on \"E(n) Equivariant Graph Neural Networks'' by Satorras, Hoogeboom and Welling https://arxiv.org/pdf/2102.09844 . I'll describe a generalization to the following situation.\n",
        "\n",
        "We'll describe an equivariant graph neural network associated to a graph $\\Gamma = (V,E)$ and a Lie group $G$.  So associated to each vertex $v_i$ of the graph we will have a variable $h_i \\in W_V$ where $W_V$ is a linear $G$-representation, and to each edge $e_{ij}$ we will have a variable $a_{ij} \\in W_E$ where $W_E$ is a linear $G$-representation.  Our model will learn $G$-equivariant functions with output encoded similarly by a graph for some new representations $W_V^{\\mathrm{out}}, W_E^{\\mathrm{out}}$.\n",
        "\n",
        "**Note:**\n",
        "\n",
        "In the paper of Satorras et al the vertex representation takes the form $\\mathbb R^n \\times W$ where $G=E(n)$ acts by isometries on the first factor and trivially on the second factor.  The isometry action is affine, not linear, but we can turn it into a linear $G$-action on $\\mathbb R^{n+1}$."
      ],
      "metadata": {
        "id": "En7h3sSID5N7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Equivariant Layer Structure\n",
        "\n",
        "Let's describe a single layer using a generalization of Satorras et al's equivariant message passing layer.  Our approach is to take as input a suitable set of $G$-equivariant polynomial functions, and build functions from linear combinations of these functions.\n",
        "\n",
        "We'll start with the message function, associated to a single edge $e_{ij}$ in the graph.  We will build equivariant functions\n",
        "$$F \\in M_I = (\\mathbb R[W_V^2 \\times W_E] \\otimes W_I)^G$$\n",
        "where $W_I$ is some intermediate $G$-representation.  This $M_I$ is a module over the algebra of invariant functions $R_I =  \\mathbb R[W_V^2 \\times W_E]^G$.\n",
        "\n",
        "We make the assumption that $R_I$ is a fininitely generated algebra with basis $f_1, \\ldots, f_n$ and that $M_I$ is finitely generated as an $R_I$-module with basis $\\mu_1, \\ldots, \\mu_N$ (for instance, this is guaranteed if $G$ is reductive).  We consider the following set of equivariant functions:\n",
        "$$\\{F^\\alpha \\colon \\alpha \\in A\\} = \\{\\mu_l\\} \\cup \\{f_k \\cdot \\mu_l\\}.$$\n",
        "Note that this set might not be linearly independent, there may be linear relations (syzygys) between the elements, leading to some potential redundancy in functions represented as linear combinations.\n",
        "\n",
        "The interpretation here is that we are generalizing the set of affine functions (sums of linear functions and constant functions) between vector spaces by including lowest order and next-to-lowest order generators.\n",
        "\n",
        "So we can now define the possible message functions.  These will take the form\n",
        "$$m_{ij} = \\sigma_I \\left(\\sum_{\\alpha \\in A} a_\\alpha f^\\alpha(h_i, h_j, a_{ij})  \\right)$$\n",
        "for some learnable coefficients $a_\\alpha$, and some pointwise activation function $\\sigma_I$.\n",
        "\n",
        "We can use these message functions to update the vertex and edge variables.  We will again construct sets of invariant functions\n",
        "\\begin{align}\n",
        "g^\\beta &\\in (\\mathbb R[W_V \\times W_I] \\otimes W_V^{\\mathrm{out}})^G \\\\\n",
        "k^\\gamma &\\in (\\mathbb R[W_E \\times W_I] \\otimes W_E^{\\mathrm{out}})^G\n",
        "\\end{align}\n",
        "in exactly the same way.  If we choose another activation function $\\sigma$ then the updated vertex and edge variables are given as follows:\n",
        "\\begin{align}\n",
        "h_i^{\\mathrm{out}} &= \\sigma \\left(b_\\beta g^\\beta\\left(h_i, \\sum_{v_j \\in N(v_i)} m_{ij} \\right) \\right) \\\\\n",
        "a_{ij}^{\\mathrm{out}} &= \\sigma \\left(c_\\gamma k^\\gamma\\left(a_{ij}, \\sum_{v_\\ell \\in N(v_i)} m_{i\\ell} + \\sum_{v_\\ell \\in N(v_j)} m_{j\\ell}  \\right) \\right)\n",
        "\\end{align}\n",
        "where again $b_\\beta, c_\\gamma$ are learnable weights, and where we write $N(v_i)$ for the neighborhood of vertex $v_i$ in the graph $\\Gamma$."
      ],
      "metadata": {
        "id": "umLhZLf2QfPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example 1:\n",
        "\n",
        "We can check that if $G$ is trivial then we recover a usual graph neural network architecture.  Indeed, in the trivial case, when we study functions $W_1 \\to W_2$, the generators in our model are given as follows.\n",
        "\n",
        "*   Generators of $W_2$ as an $\\mathbb R[W_1]$-module -- basis vectors $e^{(2)}_i$\n",
        "*   The product of generators of $W_2$ with algebra generators of $\\mathbb R[W_1]$ -- tensors of the form $(e^{(1)}_j)^* \\otimes e^{(2)}_i$.  In other words, matrix elements in $W_1^* \\otimes W_2$.\n",
        "\n",
        "Linear combinations of the first type of element generate constant functions $W_1 \\to W_2$, and linear combinations of the second type of element generate linear functions $W_1 \\to W_2$.  So altogether when we take arbitrary linear combinations in our model we are just considering the set of affine functions."
      ],
      "metadata": {
        "id": "bEeHFM9yiUmU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Example 2:\n",
        "\n",
        "Let's consider the example of Satorras, Hoogeboom and Welling.  So let $G = E(n)$, let $W_E$ be a trivial representation, and let $W_V = \\mathbb R^{n+1} \\times U$ where $U$ is again a trivial representation, and $E(n)$ acts on $\\mathbb R^{n+1} = \\mathbb R^n \\times \\mathbb R$ by affine transformations:\n",
        "$$(C,b) \\cdot (v, t) = (Cv + tb, t).$$\n",
        "We obtain the usual affine action on $\\mathbb R^n$ by restricting to the hyperplane $t=1$, and we will restrict attention to $E(n)$-equivariant functions that preserve this hyperplane.\n",
        "\n",
        "**One Spatial Input**\n",
        "\n",
        "Let us start by analyzing the equivariant functions of the form\n",
        "$$F \\colon \\mathbb R^{n+1} \\times U_1 \\to \\mathbb R^{n+1} \\times U_2$$\n",
        "where $U_1, U_2$ are trivial representations.  So according to our procedure we will need to compute algebra generators for $$A = \\mathbb R[\\mathbb R^{n+1} \\times U_1]^{E(n)}$$ and module generators for $$M = (\\mathbb R[\\mathbb R^{n+1} \\times U_1] \\otimes (\\mathbb R^{n+1} \\times U_2))^{E(n)}.$$  In each case we will restrict to those functions that preserve the $(n+1)^{\\text{st}}$ coordinate in $\\mathbb R^{n+1}$.\n",
        "\n",
        "In the first case $A \\cong \\mathbb R[\\mathbb R^{n+1}]^{E(n)} \\otimes \\mathbb R[U_1]$, and the only generators that preserve the final coordinate are constant in the first factor, so we have generators associated to basis vectors in $U_1$.\n",
        "\n",
        "In the latter case, $M$ is generated as a module by constant functions to $U_2$ together with the identity function $\\mathbb R^{n+1} \\to \\mathbb R^{n+1}$.  So, altogether, the set of zeroth and first order generating functions can be identified with $$\\{f^\\alpha\\} \\cong \\langle \\mathrm{id}\\rangle \\oplus U_2 \\oplus (U_1^* \\otimes \\langle\\mathrm{id}\\rangle) \\oplus (U_1^* \\otimes U_2).$$\n",
        "\n",
        "**Two Spatial Inputs**\n",
        "\n",
        "Finally, associated to the intermediate term we have a variant of this computation.  We need to compute algebra generators for $$A = \\mathbb R[(\\mathbb R^{n+1})^2 \\times U_1]^{E(n)}$$ and module generators for $$M = (\\mathbb R[(\\mathbb R^{n+1})^2 \\times U_1] \\otimes (\\mathbb R^{n+1} \\times U_2))^{E(n)},$$\n",
        "again preserving the hyperplane where the final coordinate in $\\mathbb R^{n+1}$ is equal to one.\n",
        "\n",
        "Let us use the notation $((x_1, t_1), (x_2, t_2)) \\in (\\mathbb R^{n+1})^2$. The algebra $A$ now has generators associated to basis vectors in $U_1$, but in addition we have a quadratic generator of the form $\\|x_1 - x_2\\|^2$.  The module $M$ still has module generators associated to constant functions to $U_2$, but rather than the identity there are now two additional generators associated to the projections $\\pi_1, \\pi_2$ onto the two factors of $(\\mathbb R^{n+1})^2$.  So now, altogether, the set of zeroth and first order generating functions can be identified with\n",
        "$$\\{f^\\alpha\\} \\cong \\langle \\pi_1, \\pi_2 \\rangle \\oplus U_2 \\oplus (U_1^* \\otimes \\langle \\pi_1, \\pi_2 \\rangle) \\oplus (\\langle \\|x_1 - x_2 \\|^2 \\rangle \\otimes \\langle \\pi_1, \\pi_2 \\rangle) \\oplus (U_1^* \\otimes U_2) \\oplus (U_1^* \\otimes \\langle \\|x_1 - x_2 \\|^2 \\rangle).$$\n",
        "In order to preserve the hyperplane we will need to restrict attention to those linear combinations $a_1 \\pi_1 + a_2 \\pi_2$ where $a_1 + a_2 = 1$.\n",
        "\n"
      ],
      "metadata": {
        "id": "OhTOk5LEgo0S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Implementation\n",
        "\n",
        "Let's go ahead and implement the equivariant graph convolution layer following this procedure.  Note that Satorras et al actually allow their message passing and vertex update terms to contain two layers: linear -> activation -> linear -> activation (where the second activation may be constant).  I will include this behaviour as an option if desired so that we can compare the results with one and two layers."
      ],
      "metadata": {
        "id": "RqdbXUj-UuYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from typing import Dict\n",
        "import torch.nn.functional as F\n",
        "import torch.cuda as cuda\n",
        "import time\n",
        "\n",
        "class EGCL(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_vertices: int,\n",
        "        adj_matrix: torch.Tensor,\n",
        "        vertex_inputs: int,\n",
        "        edge_inputs: int,\n",
        "        vertex_outputs: int,\n",
        "        edge_outputs: int,\n",
        "        inter_vars: int,\n",
        "        inter_invt_funs: list,\n",
        "        vertex_invt_funs: list,\n",
        "        edge_invt_funs: list,\n",
        "        inter_activation: callable,\n",
        "        vertex_activation: callable,\n",
        "        edge_activation: callable,\n",
        "        double_layer: bool = False,\n",
        "        inter_vars_2: int = None,\n",
        "        vertex_hidden: int = None,\n",
        "        edge_hidden: int = None,\n",
        "        inter_activation_2: callable = None,\n",
        "        vertex_activation_2: callable = None,\n",
        "        edge_activation_2: callable = None,\n",
        "        is_affine: bool = False,\n",
        "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Equivariant Graph Convolution Layer with optional double layer processing.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        num_vertices : int\n",
        "            Number of vertices in the graph\n",
        "        adj_matrix : torch.Tensor\n",
        "            Adjacency matrix of the graph (shape: [num_vertices, num_vertices])\n",
        "        vertex_inputs : int\n",
        "            Dimension of vertex input features\n",
        "        edge_inputs : int\n",
        "            Dimension of edge input features\n",
        "        vertex_outputs : int\n",
        "            Dimension of vertex output features\n",
        "        edge_outputs : int\n",
        "            Dimension of edge output features\n",
        "        inter_vars : int\n",
        "            Dimension of intermediate message features\n",
        "        inter_invt_funs : list\n",
        "            List of invariant functions for message passing\n",
        "        vertex_invt_funs : list\n",
        "            List of invariant functions for vertex updates\n",
        "        edge_invt_funs : list\n",
        "            List of invariant functions for edge updates\n",
        "        inter_activation : callable\n",
        "            Activation function for intermediate computations\n",
        "        vertex_activation : callable\n",
        "            Activation function for vertex updates\n",
        "        edge_activation : callable\n",
        "            Activation function for edge updates\n",
        "        double_layer : bool\n",
        "            Whether to use double layer processing (default: False)\n",
        "        inter_vars_2 : int\n",
        "            Dimension of second intermediate layer (default: same as inter_vars)\n",
        "        vertex_hidden : int\n",
        "            Dimension of hidden layer in vertex update (default: same as vertex_outputs)\n",
        "        edge_hidden : int\n",
        "            Dimension of hidden layer in edge update (default: same as edge_outputs)\n",
        "        inter_activation_2 : callable\n",
        "            Second activation for message passing (default: same as inter_activation)\n",
        "        vertex_activation_2 : callable\n",
        "            Second activation for vertex update (default: same as vertex_activation)\n",
        "        edge_activation_2 : callable\n",
        "            Second activation for edge update (default: same as edge_activation)\n",
        "        is_affine : bool\n",
        "            Whether to normalize outputs to preserve affine transformations\n",
        "        device : str\n",
        "            Device to run computations on\n",
        "        \"\"\"\n",
        "        super(EGCL, self).__init__()\n",
        "\n",
        "        # Validate inputs\n",
        "        if not isinstance(adj_matrix, torch.Tensor):\n",
        "            adj_matrix = torch.tensor(adj_matrix, dtype=torch.float32)\n",
        "        if adj_matrix.shape != (num_vertices, num_vertices):\n",
        "            raise ValueError(f\"adj_matrix shape {adj_matrix.shape} doesn't match num_vertices {num_vertices}\")\n",
        "\n",
        "        # Store basic parameters\n",
        "        self.device = device\n",
        "        self.num_vertices = num_vertices\n",
        "        self.adj_matrix = adj_matrix.to(device)\n",
        "        self.vertex_inputs = vertex_inputs\n",
        "        self.edge_inputs = edge_inputs\n",
        "        self.vertex_outputs = vertex_outputs\n",
        "        self.edge_outputs = edge_outputs\n",
        "        self.inter_vars = inter_vars\n",
        "        self.inter_invt_funs = inter_invt_funs\n",
        "        self.vertex_invt_funs = vertex_invt_funs\n",
        "        self.edge_invt_funs = edge_invt_funs\n",
        "        self.inter_activation = inter_activation\n",
        "        self.vertex_activation = vertex_activation\n",
        "        self.edge_activation = edge_activation\n",
        "        self.is_affine = is_affine\n",
        "\n",
        "        self.num_inter_invts = len(inter_invt_funs)\n",
        "        self.num_vertex_invts = len(vertex_invt_funs)\n",
        "        self.num_edge_invts = len(edge_invt_funs)\n",
        "\n",
        "        self.timings = {}  # For storing timing information\n",
        "\n",
        "        # Initialize first layer weights\n",
        "        n_in = 2*vertex_inputs + edge_inputs  # Total input dimension\n",
        "        n_out = inter_vars                    # Output dimension\n",
        "        std = torch.sqrt(torch.tensor(6.0/(n_in + n_out)))\n",
        "\n",
        "        self.inter_weights = nn.Parameter(\n",
        "            torch.randn(self.num_inter_invts, device=device) * std\n",
        "        )\n",
        "\n",
        "        # For vertex update weights\n",
        "        n_in = vertex_inputs + inter_vars     # Input vertex features + message features\n",
        "        n_out = vertex_outputs\n",
        "        std = torch.sqrt(torch.tensor(6.0/(n_in + n_out)))\n",
        "\n",
        "        self.vertex_weights = nn.Parameter(\n",
        "            torch.randn(self.num_vertex_invts, device=device) * std\n",
        "        )\n",
        "\n",
        "        # For edge update weights\n",
        "        n_in = edge_inputs + 2*inter_vars     # Edge features + sum of messages\n",
        "        n_out = edge_outputs\n",
        "        std = torch.sqrt(torch.tensor(6.0/(n_in + n_out)))\n",
        "\n",
        "        self.edge_weights = nn.Parameter(\n",
        "            torch.randn(self.num_edge_invts, device=device) * std\n",
        "        )\n",
        "\n",
        "        # Handle double layer parameters\n",
        "        self.double_layer = double_layer\n",
        "        if double_layer:\n",
        "            self.inter_vars_2 = inter_vars_2 if inter_vars_2 is not None else inter_vars\n",
        "            self.vertex_hidden = vertex_hidden if vertex_hidden is not None else vertex_outputs\n",
        "            self.edge_hidden = edge_hidden if edge_hidden is not None else edge_outputs\n",
        "            self.inter_activation_2 = inter_activation_2 if inter_activation_2 is not None else inter_activation\n",
        "            self.vertex_activation_2 = vertex_activation_2 if vertex_activation_2 is not None else vertex_activation\n",
        "            self.edge_activation_2 = edge_activation_2 if edge_activation_2 is not None else edge_activation\n",
        "\n",
        "            # Initialize second layer weights\n",
        "            n_in = inter_vars  # Total input dimension\n",
        "            n_out = inter_vars_2       # Output dimension\n",
        "            std = torch.sqrt(torch.tensor(6.0/(n_in + n_out)))\n",
        "\n",
        "            self.inter_weights_2 = nn.Parameter(\n",
        "                torch.randn(self.num_inter_vars_2, device=device) * std\n",
        "            )\n",
        "\n",
        "            # For vertex update weights\n",
        "            n_in = vertex_hidden   # Input vertex features + message features\n",
        "            n_out = vertex_outputs\n",
        "            std = torch.sqrt(torch.tensor(6.0/(n_in + n_out)))\n",
        "\n",
        "            self.vertex_weights_2 = nn.Parameter(\n",
        "                torch.randn(self.num_vertex_outputs, device=device) * std\n",
        "            )\n",
        "\n",
        "            # For edge update weights\n",
        "            n_in = edge_hidden    # Edge features + sum of messages\n",
        "            n_out = edge_outputs\n",
        "            std = torch.sqrt(torch.tensor(6.0/(n_in + n_out)))\n",
        "\n",
        "            self.edge_weights_2 = nn.Parameter(\n",
        "                torch.randn(self.num_edge_outputs, device=device) * std\n",
        "            )\n",
        "\n",
        "        # Pre-compute neighborhoods\n",
        "        self.neighborhoods = self._compute_neighborhoods()\n",
        "\n",
        "    def _compute_neighborhoods(self):\n",
        "        \"\"\"Pre-compute neighborhoods for each vertex.\"\"\"\n",
        "        neighborhoods = {}\n",
        "        for i in range(self.num_vertices):\n",
        "            neighborhoods[i] = torch.nonzero(self.adj_matrix[i], as_tuple=False).squeeze(1)\n",
        "        return neighborhoods\n",
        "\n",
        "    def _normalize_if_affine(self, tensor):\n",
        "        \"\"\"Normalize tensor if is_affine is True and tensor is non-zero.\"\"\"\n",
        "        if self.is_affine and torch.norm(tensor) > 1e-8:\n",
        "            return F.normalize(tensor, dim=-1)\n",
        "        return tensor\n",
        "\n",
        "    def intermediate_term(self, h_i, h_j, a_ij):\n",
        "        \"\"\"Compute message from vertex i to vertex j.\"\"\"\n",
        "        try:\n",
        "            # First layer\n",
        "            #print(f\"Computing {len(self.inter_invt_funs)} invariant functions...\")\n",
        "\n",
        "            invt_outputs = torch.stack([\n",
        "                torch.as_tensor(f(h_i, h_j, a_ij), device=self.device)\n",
        "                for f in self.inter_invt_funs\n",
        "            ])\n",
        "            message = torch.matmul(self.inter_weights, invt_outputs)\n",
        "            message = self._normalize_if_affine(message)\n",
        "            message = self.inter_activation(message)\n",
        "\n",
        "            if not self.double_layer:\n",
        "                return message\n",
        "\n",
        "            # Second layer\n",
        "            message = torch.matmul(self.inter_weights_2, message)\n",
        "            message = self._normalize_if_affine(message)\n",
        "            return self.inter_activation_2(message)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            raise RuntimeError(f\"Error in intermediate_term: {str(e)}\")\n",
        "\n",
        "    def vertex_update(self, h, m):\n",
        "        \"\"\"Update vertex features.\"\"\"\n",
        "        try:\n",
        "            # First layer\n",
        "            invt_outputs = torch.stack([\n",
        "                torch.as_tensor(f(h, m), device=self.device)\n",
        "                for f in self.vertex_invt_funs\n",
        "            ])\n",
        "            update = torch.matmul(self.vertex_weights, invt_outputs)\n",
        "            update = self._normalize_if_affine(update)\n",
        "            update = self.vertex_activation(update)\n",
        "\n",
        "            if not self.double_layer:\n",
        "                return update\n",
        "\n",
        "            # Second layer\n",
        "            update = torch.matmul(self.vertex_weights_2, update)\n",
        "            update = self._normalize_if_affine(update)\n",
        "            return self.vertex_activation_2(update)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            raise RuntimeError(f\"Error in vertex_update: {str(e)}\")\n",
        "\n",
        "    def edge_update(self, a, m):\n",
        "        \"\"\"Update edge features.\"\"\"\n",
        "        try:\n",
        "            # First layer\n",
        "            invt_outputs = torch.stack([\n",
        "                torch.as_tensor(f(a, m), device=self.device)\n",
        "                for f in self.edge_invt_funs\n",
        "            ])\n",
        "            update = torch.matmul(self.edge_weights, invt_outputs)\n",
        "            update = self._normalize_if_affine(update)\n",
        "            update = self.edge_activation(update)\n",
        "\n",
        "            if not self.double_layer:\n",
        "                return update\n",
        "\n",
        "            # Second layer\n",
        "            update = torch.matmul(self.edge_weights_2, update)\n",
        "            update = self._normalize_if_affine(update)\n",
        "            return self.edge_activation_2(update)\n",
        "\n",
        "        except RuntimeError as e:\n",
        "            raise RuntimeError(f\"Error in edge_update: {str(e)}\")\n",
        "\n",
        "    def _time_op(self, name: str, op, *args, **kwargs):\n",
        "        \"\"\"Time an operation and store result\"\"\"\n",
        "        if cuda.is_available():\n",
        "            cuda.synchronize()  # Ensure GPU ops complete\n",
        "        start = time.perf_counter()\n",
        "        result = op(*args, **kwargs)\n",
        "        if cuda.is_available():\n",
        "            cuda.synchronize()\n",
        "        duration = time.perf_counter() - start\n",
        "\n",
        "        if name not in self.timings:\n",
        "            self.timings[name] = []\n",
        "        self.timings[name].append(duration)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def forward(self, h_graph: torch.Tensor, a_graph: torch.Tensor):\n",
        "        \"\"\"\n",
        "        Forward pass of the layer.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        h_graph : torch.Tensor\n",
        "            Vertex features (shape: [num_vertices, vertex_inputs])\n",
        "        a_graph : torch.Tensor\n",
        "            Edge features (shape: [num_vertices, num_vertices, edge_inputs])\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        tuple(torch.Tensor, torch.Tensor)\n",
        "            Updated vertex and edge features\n",
        "        \"\"\"\n",
        "        if h_graph.shape != (self.num_vertices, self.vertex_inputs):\n",
        "            raise ValueError(f\"h_graph shape {h_graph.shape} doesn't match expected shape\"\n",
        "                           f\" ({self.num_vertices}, {self.vertex_inputs})\")\n",
        "        if a_graph.shape != (self.num_vertices, self.num_vertices, self.edge_inputs):\n",
        "            raise ValueError(f\"a_graph shape {a_graph.shape} doesn't match expected shape\"\n",
        "                           f\" ({self.num_vertices}, {self.num_vertices}, {self.edge_inputs})\")\n",
        "\n",
        "        print(\"EGCL forward pass starting...\")\n",
        "        self.timings = {}\n",
        "\n",
        "        # Move inputs to correct device\n",
        "        h_graph = h_graph.to(self.device)\n",
        "        a_graph = a_graph.to(self.device)\n",
        "\n",
        "        # Initialize output tensors\n",
        "        h_graph_out = torch.zeros(\n",
        "            (self.num_vertices, self.vertex_outputs),\n",
        "            device=self.device\n",
        "        )\n",
        "        a_graph_out = torch.zeros(\n",
        "            (self.num_vertices, self.num_vertices, self.edge_outputs),\n",
        "            device=self.device\n",
        "        )\n",
        "\n",
        "        # Compute messages for all edges\n",
        "        \"\"\"\n",
        "        messages = torch.zeros(\n",
        "            (self.num_vertices, self.num_vertices, self.inter_vars),\n",
        "            device=self.device\n",
        "        )\n",
        "        \"\"\"\n",
        "        messages = self._time_op(\n",
        "            \"init_messages\",\n",
        "            lambda: torch.zeros(\n",
        "                (self.num_vertices, self.num_vertices, self.inter_vars),\n",
        "                device=self.device\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Get active edges\n",
        "        edge_indices = torch.triu_indices(self.num_vertices, self.num_vertices, 1).to(self.device)\n",
        "        edge_mask = self.adj_matrix[edge_indices[0], edge_indices[1]] > 0\n",
        "        edge_indices = (edge_indices[0][edge_mask], edge_indices[1][edge_mask])\n",
        "        num_edges = len(edge_indices[0])\n",
        "\n",
        "        # Compute messages only for existing edges\n",
        "        \"\"\"\n",
        "        for idx, (i, j) in enumerate(zip(*edge_indices)):\n",
        "            messages[i, j] = self.intermediate_term(h_graph[i], h_graph[j], a_graph[i, j])\n",
        "            messages[j, i] = self.intermediate_term(h_graph[j], h_graph[i], a_graph[j, i])\n",
        "        \"\"\"\n",
        "\n",
        "        for idx, (i, j) in enumerate(zip(*edge_indices)):\n",
        "            messages[i, j] = self._time_op(\n",
        "                \"intermediate_term\",\n",
        "                self.intermediate_term,\n",
        "                h_graph[i], h_graph[j], a_graph[i, j]\n",
        "            )\n",
        "            messages[j, i] = self.intermediate_term(h_graph[j], h_graph[i], a_graph[j, i])\n",
        "\n",
        "        #print(\"Computing message sums...\")\n",
        "        \"\"\"\n",
        "        message_sums = torch.sum(\n",
        "            messages * self.adj_matrix.unsqueeze(-1),\n",
        "            dim=1\n",
        "        )\n",
        "        \"\"\"\n",
        "        message_sums = self._time_op(\n",
        "            \"message_sums\",\n",
        "            lambda: torch.sum(\n",
        "                messages * self.adj_matrix.unsqueeze(-1),\n",
        "                dim=1\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # print(f\"Updating vertices...\")\n",
        "        \"\"\"\n",
        "        for i in range(self.num_vertices):\n",
        "            h_graph_out[i] = self.vertex_update(h_graph[i], message_sums[i])\n",
        "        \"\"\"\n",
        "        for i in range(self.num_vertices):\n",
        "            h_graph_out[i] = self._time_op(\n",
        "                \"vertex_update\",\n",
        "                self.vertex_update,\n",
        "                h_graph[i], message_sums[i]\n",
        "            )\n",
        "\n",
        "        #print(f\"Updating edges...\")\n",
        "        \"\"\"\n",
        "        for i, j in zip(*edge_indices):\n",
        "            a_graph_out[i, j] = self.edge_update(\n",
        "                a_graph[i, j],\n",
        "                message_sums[i] + message_sums[j]\n",
        "            )\n",
        "        \"\"\"\n",
        "        for i, j in zip(*edge_indices):\n",
        "            a_graph_out[i, j] = self._time_op(\n",
        "                \"edge_update\",\n",
        "                self.edge_update,\n",
        "                a_graph[i, j],\n",
        "                message_sums[i] + message_sums[j]\n",
        "            )\n",
        "\n",
        "        # Print timing summary\n",
        "        print(\"\\nEGCL Layer Timing Summary:\")\n",
        "        for op, times in self.timings.items():\n",
        "            avg_time = sum(times) / len(times)\n",
        "            total_time = sum(times)\n",
        "            print(f\"{op:20s} - Avg: {avg_time:.4f}s, Total: {total_time:.4f}s, Count: {len(times)}\")\n",
        "\n",
        "\n",
        "        #print(\"Forward pass complete\")\n",
        "        return h_graph_out, a_graph_out"
      ],
      "metadata": {
        "id": "yTNOgXMePV4X"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's start by testing the layer with an example.  I'll let $G = E(3)$ and use the fundamental representation $\\mathbb R^4$ for the vertex space $W_V$ and intermediate space and the trivial representation $\\mathbb R$ for the edge space $W_E$.  I'll just list the invariant functions defined individually."
      ],
      "metadata": {
        "id": "VAxY7_T5n2uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_vertices = 5\n",
        "adj_matrix = torch.randint(0,2,(num_vertices, num_vertices))\n",
        "adj_matrix = (adj_matrix + adj_matrix.T) / 2\n",
        "\n",
        "def inter_invt_fun1(h_i, h_j, a_ij):\n",
        "    return h_i\n",
        "\n",
        "def inter_invt_fun2(h_i, h_j, a_ij):\n",
        "    return h_j\n",
        "\n",
        "def inter_invt_fun3(h_i, h_j, a_ij):\n",
        "    return a_ij * h_i\n",
        "\n",
        "def inter_invt_fun4(h_i, h_j, a_ij):\n",
        "    return a_ij * h_j\n",
        "\n",
        "def inter_invt_fun5(h_i, h_j, a_ij):\n",
        "    return h_i * torch.linalg.norm(h_i - h_j) ** 2\n",
        "\n",
        "def inter_invt_fun6(h_i, h_j, a_ij):\n",
        "    return h_j * torch.linalg.norm(h_i - h_j) ** 2\n",
        "\n",
        "def vertex_invt_fun1(h, m):\n",
        "    return h\n",
        "\n",
        "def vertex_invt_fun2(h, m):\n",
        "    return m\n",
        "\n",
        "def vertex_invt_fun3(h, m):\n",
        "    return h * torch.linalg.norm(h - m) ** 2\n",
        "\n",
        "def vertex_invt_fun4(h, m):\n",
        "    return m * torch.linalg.norm(h - m) ** 2\n",
        "\n",
        "\n",
        "def edge_invt_fun(a, m):\n",
        "    return a\n",
        "\n",
        "inter_invt_funs = [\n",
        "    inter_invt_fun1,\n",
        "    inter_invt_fun2,\n",
        "    inter_invt_fun3,\n",
        "    inter_invt_fun4,\n",
        "    inter_invt_fun5,\n",
        "    inter_invt_fun6\n",
        "]\n",
        "\n",
        "vertex_invt_funs = [\n",
        "    vertex_invt_fun1,\n",
        "    vertex_invt_fun2,\n",
        "    vertex_invt_fun3,\n",
        "    vertex_invt_fun4\n",
        "]\n",
        "\n",
        "edge_invt_funs = [edge_invt_fun]"
      ],
      "metadata": {
        "id": "N53llv26dhSr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer = EGCL(\n",
        "    num_vertices=num_vertices,\n",
        "    adj_matrix=adj_matrix,\n",
        "    vertex_inputs=4,    # R^4 for vertex features\n",
        "    edge_inputs=1,      # R^1 for edge features (trivial rep)\n",
        "    vertex_outputs=4,   # R^4 output\n",
        "    edge_outputs=1,     # R^1 output\n",
        "    inter_vars=4,       # R^4 for intermediate representation\n",
        "    inter_invt_funs=inter_invt_funs,\n",
        "    vertex_invt_funs=vertex_invt_funs,\n",
        "    edge_invt_funs=edge_invt_funs,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True     # We are using an affine group so should rescale to preserve a hyperplane\n",
        ")\n",
        "\n",
        "# Create some example input data\n",
        "h_graph = torch.randn(num_vertices, 4)  # Random vertex features in R^4\n",
        "a_graph = torch.randn(num_vertices, num_vertices, 1)  # Random edge features\n",
        "\n",
        "# Forward pass\n",
        "h_out, a_out = layer(h_graph, a_graph)\n",
        "\n",
        "print(f\"Input vertex features shape: {h_graph.shape}\")\n",
        "print(f\"Output vertex features shape: {h_out.shape}\")\n",
        "print(f\"Input edge features shape: {a_graph.shape}\")\n",
        "print(f\"Output edge features shape: {a_out.shape}\")\n",
        "\n",
        "# Print statistics before and after activation\n",
        "def print_activation_stats(tensor, name):\n",
        "    print(f\"\\n{name} statistics:\")\n",
        "    print(f\"Min: {tensor.min():.4f}\")\n",
        "    print(f\"Max: {tensor.max():.4f}\")\n",
        "    print(f\"Mean: {tensor.mean():.4f}\")\n",
        "    print(f\"Std: {tensor.std():.4f}\")\n",
        "\n",
        "# Get pre-activation values (you'd need to modify the layer to expose these)\n",
        "print_activation_stats(h_out, \"Vertex outputs\")\n",
        "print_activation_stats(a_out, \"Edge outputs\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPpoPLEfvDYy",
        "outputId": "b2d52da7-9c2e-4170-a531-c0116c5c9fd9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.0005s, Total: 0.0044s, Count: 9\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0005s, Total: 0.0023s, Count: 5\n",
            "edge_update          - Avg: 0.0003s, Total: 0.0028s, Count: 9\n",
            "Input vertex features shape: torch.Size([5, 4])\n",
            "Output vertex features shape: torch.Size([5, 4])\n",
            "Input edge features shape: torch.Size([5, 5, 1])\n",
            "Output edge features shape: torch.Size([5, 5, 1])\n",
            "\n",
            "Vertex outputs statistics:\n",
            "Min: 0.0000\n",
            "Max: 0.4412\n",
            "Mean: 0.0453\n",
            "Std: 0.1160\n",
            "\n",
            "Edge outputs statistics:\n",
            "Min: 0.0000\n",
            "Max: 1.0000\n",
            "Mean: 0.1600\n",
            "Std: 0.3742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Building $E(n)$ Equivariant Models\n",
        "\n",
        "The next step is to build a model.  I'll stick with the $E(n)$ example, and representations of the form $(\\mathbb R^{n+1})^a \\times \\mathbb R^b$ -- products of the fundamental and trivial representations.  I'll need a general method for constructing the sets of generating equivariant functions.\n",
        "\n",
        "Let's consider equivariant functions\n",
        "$$F \\colon (\\mathbb R^{n+1})^a \\times \\mathbb R^b \\to (\\mathbb R^{n+1})^c \\times \\mathbb R^d.$$\n",
        "The set of $\\mathrm O(n)$-equivariant functions we will wish to generate will consist of\n",
        "$$\\{x_{ij}, e_{kl}, \\langle x_p, x_q \\rangle x_{ij}, \\langle x_p, x_q \\rangle e_{kl}, e_r x_{ij}, e_r e_{kl}\\}$$\n",
        "where $x_{ij}, e_{kl}$ are the matrix element functions in the first and second factors respectively, and where $x_p, e_r$ are coordinate functions on the $p^\\text{th}$ factor of $(\\mathbb R^{n+1})^a$ and the $r^\\text{th}$ factor of $\\mathbb R^b$ respectively.  To be additionally translation equivariant we must restrict the inner product terms to those generated by $\\langle x_p, x_q \\rangle - \\langle x_p, x_{q'} \\rangle$, and the $x_{ij}$ terms to linear combinations with coefficients summing to one.\n"
      ],
      "metadata": {
        "id": "ziO65nhlVBrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Tuple, Callable, Optional\n",
        "\n",
        "class EnRepresentation:\n",
        "    \"\"\"\n",
        "    Handles E(n) representations of the form (R^(n+1))^a Ã— R^b\n",
        "    \"\"\"\n",
        "    def __init__(self, dim: int, num_vectors: int, num_scalars: int):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            dim: Dimension n of the ambient spacetime\n",
        "            num_vectors: Number of R^(n+1) factors\n",
        "            num_scalars: Dimension of factors\n",
        "        \"\"\"\n",
        "        self.dim = dim\n",
        "        self.num_vectors = num_vectors\n",
        "        self.num_scalars = num_scalars\n",
        "\n",
        "    def total_dim(self) -> int:\n",
        "        \"\"\"Total dimension of representation space.\"\"\"\n",
        "        return (self.dim + 1) * self.num_vectors + self.num_scalars\n",
        "\n",
        "    def split_vector_scalar(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Split tensor into vector and scalar parts.\"\"\"\n",
        "        vector_dim = (self.dim + 1) * self.num_vectors\n",
        "        return x[:vector_dim], x[vector_dim:]\n",
        "\n",
        "    def combine_vector_scalar(self, vectors: torch.Tensor, scalars: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Combine vector and scalar parts.\"\"\"\n",
        "        return torch.cat([vectors, scalars])\n",
        "\n",
        "def generate_En_message_invariants(\n",
        "    dim: int,\n",
        "    vertex_rep: EnRepresentation,  # Vertex rep\n",
        "    edge_rep: EnRepresentation,  # Edge rep\n",
        "    out_rep: EnRepresentation   # Output rep\n",
        ") -> List[Callable]:\n",
        "    \"\"\"\n",
        "    Generate E(n)-equivariant functions for message passing.\n",
        "    \"\"\"\n",
        "    invariants = []\n",
        "\n",
        "    def make_linear_vector_invariant(i: int, j: int) -> Callable:\n",
        "        \"\"\"Create linear invariant function for vector factor.\"\"\"\n",
        "        def f(h1: torch.Tensor, h2: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
        "            v1, s1 = vertex_rep.split_vector_scalar(h1)\n",
        "            v2, s2 = vertex_rep.split_vector_scalar(h2)\n",
        "            ve, se = edge_rep.split_vector_scalar(e)\n",
        "\n",
        "            out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h1.device)\n",
        "            out_s = torch.zeros(out_rep.num_scalars, device=h1.device)\n",
        "\n",
        "            if i < vertex_rep.num_vectors:\n",
        "                out_v[j*(dim + 1):(j+1)*(dim + 1)] = v1[i*(dim + 1):(i+1)*(dim + 1)]\n",
        "            elif i < vertex_rep.num_vectors * 2:\n",
        "                i2 = i - vertex_rep.num_vectors\n",
        "                out_v[j*(dim + 1):(j+1)*(dim + 1)] = v2[i2*(dim + 1):(i2+1)*(dim + 1)]\n",
        "\n",
        "            return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_linear_scalar_invariant(k: int, l: int) -> Callable:\n",
        "        \"\"\"Create linear invariant function for scalar factor.\"\"\"\n",
        "        def f(h1: torch.Tensor, h2: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
        "          v1, s1 = vertex_rep.split_vector_scalar(h1)\n",
        "          v2, s2 = vertex_rep.split_vector_scalar(h2)\n",
        "          ve, se = edge_rep.split_vector_scalar(e)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h1.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h1.device)\n",
        "\n",
        "          if k < vertex_rep.num_scalars:\n",
        "            out_s[l] = s1[k]\n",
        "          elif k < vertex_rep.num_scalars * 2:\n",
        "            k2 = k - vertex_rep.num_scalars\n",
        "            out_s[l] = s2[k2]\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_quadratic_vector_invariant(i: int, j: int, r: int) -> Callable:\n",
        "        \"\"\"Create quadratic invariant function x_ij e_r.\"\"\"\n",
        "        def f(h1: torch.Tensor, h2: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
        "            v1, s1 = vertex_rep.split_vector_scalar(h1)\n",
        "            v2, s2 = vertex_rep.split_vector_scalar(h2)\n",
        "            ve, se = edge_rep.split_vector_scalar(e)\n",
        "\n",
        "            out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h1.device)\n",
        "            out_s = torch.zeros(out_rep.num_scalars, device=h1.device)\n",
        "\n",
        "            g = make_linear_vector_invariant(i,j)\n",
        "            lin_v, lin_s = out_rep.split_vector_scalar(g(h1, h2, e))\n",
        "            if r < vertex_rep.num_scalars:\n",
        "                out_v = lin_v * s1[r]\n",
        "            elif r < vertex_rep.num_scalars * 2:\n",
        "                r2 = r - vertex_rep.num_scalars\n",
        "                out_v = lin_v * s2[r2]\n",
        "\n",
        "            return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_quadratic_scalar_invariant(k: int, l: int, r: int) -> Callable:\n",
        "        \"\"\"Create quadratic invariant function e_kl e_r.\"\"\"\n",
        "        def f(h1: torch.Tensor, h2: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
        "            v1, s1 = vertex_rep.split_vector_scalar(h1)\n",
        "            v2, s2 = vertex_rep.split_vector_scalar(h2)\n",
        "            ve, se = edge_rep.split_vector_scalar(e)\n",
        "\n",
        "            out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h1.device)\n",
        "            out_s = torch.zeros(out_rep.num_scalars, device=h1.device)\n",
        "\n",
        "            g = make_linear_scalar_invariant(k,l)\n",
        "            lin_v, lin_s = out_rep.split_vector_scalar(g(h1, h2, e))\n",
        "            if r < vertex_rep.num_scalars:\n",
        "                out_s = lin_s * s1[r]\n",
        "            elif r < vertex_rep.num_scalars * 2:\n",
        "                r2 = r - vertex_rep.num_scalars\n",
        "                out_s = lin_s * s2[r2]\n",
        "\n",
        "            return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_cubic_vector_invariant(i: int, j: int, p: int, q: int) -> Callable:\n",
        "        \"\"\"Create cubic invariant function <x_p, x_q> x_ij.\"\"\"\n",
        "        def f(h1: torch.Tensor, h2: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
        "          v1, s1 = vertex_rep.split_vector_scalar(h1)\n",
        "          v2, s2 = vertex_rep.split_vector_scalar(h2)\n",
        "          ve, se = edge_rep.split_vector_scalar(e)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h1.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h1.device)\n",
        "\n",
        "          if p < vertex_rep.num_vectors:\n",
        "            w1 = v1[p*(dim + 1):(p+1)*(dim + 1)]\n",
        "          elif p < vertex_rep.num_vectors * 2:\n",
        "            p2 = p - vertex_rep.num_vectors\n",
        "            w1 = v2[p2*(dim + 1):(p2+1)*(dim + 1)]\n",
        "\n",
        "          if q < vertex_rep.num_vectors:\n",
        "            w2 = v1[q*(dim + 1):(q+1)*(dim + 1)]\n",
        "          elif q < vertex_rep.num_vectors * 2:\n",
        "            q2 = q - vertex_rep.num_vectors\n",
        "            w2 = v2[q2*(dim + 1):(q2+1)*(dim + 1)]\n",
        "\n",
        "          g = make_linear_vector_invariant(i,j)\n",
        "          lin_v, lin_s = out_rep.split_vector_scalar(g(h1, h2, e))\n",
        "          out_v = lin_v * torch.dot(w1, w2)\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_cubic_scalar_invariant(k: int, l: int, p: int, q: int) -> Callable:\n",
        "        \"\"\"Create cubic invariant function <x_p, x_q> e_kl.\"\"\"\n",
        "        def f(h1: torch.Tensor, h2: torch.Tensor, e: torch.Tensor) -> torch.Tensor:\n",
        "          v1, s1 = vertex_rep.split_vector_scalar(h1)\n",
        "          v2, s2 = vertex_rep.split_vector_scalar(h2)\n",
        "          ve, se = edge_rep.split_vector_scalar(e)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h1.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h1.device)\n",
        "\n",
        "          if p < vertex_rep.num_vectors:\n",
        "            w1 = v1[p*(dim + 1):(p+1)*(dim + 1)]\n",
        "          elif p < vertex_rep.num_vectors * 2:\n",
        "            p2 = p - vertex_rep.num_vectors\n",
        "            w1 = v2[p2*(dim + 1):(p2+1)*(dim + 1)]\n",
        "\n",
        "          if q < vertex_rep.num_vectors:\n",
        "            w2 = v1[q*(dim + 1):(q+1)*(dim + 1)]\n",
        "          elif q < vertex_rep.num_vectors * 2:\n",
        "            q2 = q - vertex_rep.num_vectors\n",
        "            w2 = v2[q2*(dim + 1):(q2+1)*(dim + 1)]\n",
        "\n",
        "          g = make_linear_scalar_invariant(k,l)\n",
        "          lin_v, lin_s = out_rep.split_vector_scalar(g(h1, h2, e))\n",
        "          out_v = lin_v * torch.dot(w1, w2)\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "\n",
        "    # Add linear invariants\n",
        "    for i in range(vertex_rep.num_vectors *2):\n",
        "        for j in range(out_rep.num_vectors):\n",
        "            invariants.append(make_linear_vector_invariant(i, j))\n",
        "\n",
        "    for k in range(vertex_rep.num_scalars *2):\n",
        "        for l in range(out_rep.num_scalars):\n",
        "            invariants.append(make_linear_scalar_invariant(k, l))\n",
        "\n",
        "    # Add quadratic invariants\n",
        "    for i in range(vertex_rep.num_vectors *2):\n",
        "        for j in range(out_rep.num_vectors):\n",
        "            for r in range(vertex_rep.num_scalars * 2):\n",
        "                invariants.append(make_quadratic_vector_invariant(i, j, r))\n",
        "\n",
        "    for k in range(vertex_rep.num_scalars *2):\n",
        "        for l in range(out_rep.num_scalars):\n",
        "            for r in range(vertex_rep.num_scalars * 2):\n",
        "              invariants.append(make_quadratic_scalar_invariant(k, l, r))\n",
        "\n",
        "    # Add cubic invariants.  We need to generate differences like <x_p, x_q - x_{q+1}>x_ij\n",
        "\n",
        "    def make_difference(f1, f2):\n",
        "                      def diff(h1, h2, e):\n",
        "                          return f1(h1, h2, e) - f2(h1, h2, e)\n",
        "                      return diff\n",
        "\n",
        "    for i in range(vertex_rep.num_vectors *2):\n",
        "        for j in range(out_rep.num_vectors):\n",
        "            for p in range(vertex_rep.num_vectors *2):\n",
        "                for q in range(vertex_rep.num_vectors):\n",
        "                  next_q = (q + 1) % vertex_rep.num_vectors  # Cyclic index\n",
        "                  f_current = make_cubic_vector_invariant(i, j, p, q)\n",
        "                  f_next = make_cubic_vector_invariant(i, j, p, next_q)\n",
        "\n",
        "                  invariants.append(make_difference(f_current, f_next))\n",
        "\n",
        "                base_q = vertex_rep.num_vectors\n",
        "                for q_offset in range(vertex_rep.num_vectors):\n",
        "                   q = base_q + q_offset\n",
        "                   next_q = base_q + ((q_offset + 1) % vertex_rep.num_vectors)\n",
        "                   g_current = make_cubic_vector_invariant(i, j, p, q)\n",
        "                   g_next = make_cubic_vector_invariant(i, j, p, next_q)\n",
        "\n",
        "                   invariants.append(make_difference(g_current, g_next))\n",
        "\n",
        "    for k in range(vertex_rep.num_scalars *2):\n",
        "        for l in range(out_rep.num_scalars):\n",
        "          for p in range(vertex_rep.num_vectors *2):\n",
        "                for q in range(vertex_rep.num_vectors):\n",
        "                  next_q = (q + 1) % vertex_rep.num_vectors  # Cyclic index\n",
        "                  f_current = make_cubic_scalar_invariant(k, l, p, q)\n",
        "                  f_next = make_cubic_scalar_invariant(k, l, p, next_q)\n",
        "\n",
        "                  invariants.append(make_difference(f_current, f_next))\n",
        "\n",
        "                base_q = vertex_rep.num_vectors\n",
        "                for q_offset in range(vertex_rep.num_vectors):\n",
        "                   q = base_q + q_offset\n",
        "                   next_q = base_q + ((q_offset + 1) % vertex_rep.num_vectors)\n",
        "                   g_current = make_cubic_scalar_invariant(k, l, p, q)\n",
        "                   g_next = make_cubic_scalar_invariant(k, l, p, next_q)\n",
        "\n",
        "                   invariants.append(make_difference(g_current, g_next))\n",
        "\n",
        "\n",
        "    return invariants\n",
        "\n",
        "def generate_En_vertex_edge_invariants(\n",
        "    dim: int,\n",
        "    input_rep: EnRepresentation,  # Vertex or edge rep\n",
        "    internal_rep: EnRepresentation,  # Internal variable rep\n",
        "    out_rep: EnRepresentation   # Output rep\n",
        ") -> List[Callable]:\n",
        "    \"\"\"\n",
        "    Generate E(n)-equivariant functions for message passing.\n",
        "    \"\"\"\n",
        "    invariants = []\n",
        "\n",
        "    def make_linear_vector_invariant(i: int, j: int) -> Callable:\n",
        "        \"\"\"Create linear invariant function for vector factor.\"\"\"\n",
        "        def f(h: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "            v, s = input_rep.split_vector_scalar(h)\n",
        "            vi, si = internal_rep.split_vector_scalar(m)\n",
        "\n",
        "            out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h.device)\n",
        "            out_s = torch.zeros(out_rep.num_scalars, device=h.device)\n",
        "\n",
        "            if i < input_rep.num_vectors:\n",
        "                out_v[j*(dim + 1):(j+1)*(dim + 1)] = v[i*(dim + 1):(i+1)*(dim + 1)]\n",
        "            elif i < input_rep.num_vectors + internal_rep.num_vectors:\n",
        "                i2 = i - input_rep.num_vectors\n",
        "                out_v[j*(dim + 1):(j+1)*(dim + 1)] = vi[i2*(dim + 1):(i2+1)*(dim + 1)]\n",
        "\n",
        "            return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_linear_scalar_invariant(k: int, l: int) -> Callable:\n",
        "        \"\"\"Create linear invariant function for scalar factor.\"\"\"\n",
        "        def f(h: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "          v, s = input_rep.split_vector_scalar(h)\n",
        "          vi, si = internal_rep.split_vector_scalar(m)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h.device)\n",
        "\n",
        "          if k < input_rep.num_scalars:\n",
        "            out_s[l] = s[k]\n",
        "          elif k < input_rep.num_scalars + internal_rep.num_scalars:\n",
        "            k2 = k - input_rep.num_scalars\n",
        "            out_s[l] = si[k2]\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_quadratic_vector_invariant(i: int, j: int, r: int) -> Callable:\n",
        "        \"\"\"Create quadratic invariant function x_ij e_r.\"\"\"\n",
        "        def f(h: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "            v, s = input_rep.split_vector_scalar(h)\n",
        "            vi, si = internal_rep.split_vector_scalar(m)\n",
        "\n",
        "            out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h.device)\n",
        "            out_s = torch.zeros(out_rep.num_scalars, device=h.device)\n",
        "\n",
        "            g = make_linear_vector_invariant(i,j)\n",
        "            lin_v, lin_s = out_rep.split_vector_scalar(g(h, m))\n",
        "            if r < input_rep.num_scalars:\n",
        "                out_v = lin_v * s[r]\n",
        "            elif r < input_rep.num_scalars + internal_rep.num_scalars:\n",
        "                r2 = r - input_rep.num_scalars\n",
        "                out_v = lin_v * si[r2]\n",
        "\n",
        "            return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_quadratic_scalar_invariant(k: int, l: int, r: int) -> Callable:\n",
        "        \"\"\"Create quadratic invariant function e_kl e_r.\"\"\"\n",
        "        def f(h: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "          v, s = input_rep.split_vector_scalar(h)\n",
        "          vi, si = internal_rep.split_vector_scalar(m)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h.device)\n",
        "\n",
        "          g = make_linear_scalar_invariant(k,l)\n",
        "          lin_v, lin_s = out_rep.split_vector_scalar(g(h, m))\n",
        "          if r < input_rep.num_scalars:\n",
        "              out_s = lin_s * s[r]\n",
        "          elif r < input_rep.num_scalars + internal_rep.num_scalars:\n",
        "              r2 = r - input_rep.num_scalars\n",
        "              out_s = lin_s * si[r2]\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_cubic_vector_invariant(i: int, j: int, p: int, q: int) -> Callable:\n",
        "        \"\"\"Create cubic invariant function <x_p, x_q> x_ij.\"\"\"\n",
        "        def f(h: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "          v, s = input_rep.split_vector_scalar(h)\n",
        "          vi, si = internal_rep.split_vector_scalar(m)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h.device)\n",
        "\n",
        "          if p < input_rep.num_vectors:\n",
        "            w1 = v[p*(dim + 1):(p+1)*(dim + 1)]\n",
        "          elif p < input_rep.num_vectors + internal_rep.num_vectors:\n",
        "            p2 = p - input_rep.num_vectors\n",
        "            w1 = vi[p2*(dim + 1):(p2+1)*(dim + 1)]\n",
        "\n",
        "          if q < input_rep.num_vectors:\n",
        "            w2 = v[q*(dim + 1):(q+1)*(dim + 1)]\n",
        "          elif q < input_rep.num_vectors + internal_rep.num_vectors:\n",
        "            q2 = q - input_rep.num_vectors\n",
        "            w2 = vi[q2*(dim + 1):(q2+1)*(dim + 1)]\n",
        "\n",
        "          g = make_linear_vector_invariant(i,j)\n",
        "          lin_v, lin_s = out_rep.split_vector_scalar(g(h, m))\n",
        "          out_v = lin_v * torch.dot(w1, w2)\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "    def make_cubic_scalar_invariant(k: int, l: int, p: int, q: int) -> Callable:\n",
        "        \"\"\"Create cubic invariant function <x_p, x_q> e_kl.\"\"\"\n",
        "        def f(h: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "          v, s = input_rep.split_vector_scalar(h)\n",
        "          vi, si = internal_rep.split_vector_scalar(m)\n",
        "\n",
        "          out_v = torch.zeros((out_rep.num_vectors * (dim + 1)), device=h.device)\n",
        "          out_s = torch.zeros(out_rep.num_scalars, device=h.device)\n",
        "\n",
        "          if p < input_rep.num_vectors:\n",
        "            w1 = v[p*(dim + 1):(p+1)*(dim + 1)]\n",
        "          elif p < input_rep.num_vectors + internal_rep.num_vectors:\n",
        "            p2 = p - input_rep.num_vectors\n",
        "            w1 = vi[p2*(dim + 1):(p2+1)*(dim + 1)]\n",
        "\n",
        "          if q < input_rep.num_vectors:\n",
        "            w2 = v[q*(dim + 1):(q+1)*(dim + 1)]\n",
        "          elif q < input_rep.num_vectors + internal_rep.num_vectors:\n",
        "            q2 = q - input_rep.num_vectors\n",
        "            w2 = vi[q2*(dim + 1):(q2+1)*(dim + 1)]\n",
        "\n",
        "          g = make_linear_scalar_invariant(k,l)\n",
        "          lin_v, lin_s = out_rep.split_vector_scalar(g(h, m))\n",
        "          out_s = lin_s * torch.dot(w1, w2)\n",
        "\n",
        "          return out_rep.combine_vector_scalar(out_v, out_s)\n",
        "        return f\n",
        "\n",
        "\n",
        "    # Add linear invariants\n",
        "    for i in range(input_rep.num_vectors + internal_rep.num_vectors):\n",
        "        for j in range(out_rep.num_vectors):\n",
        "            invariants.append(make_linear_vector_invariant(i, j))\n",
        "\n",
        "    for k in range(input_rep.num_scalars + internal_rep.num_scalars):\n",
        "        for l in range(out_rep.num_scalars):\n",
        "            invariants.append(make_linear_scalar_invariant(k, l))\n",
        "\n",
        "    # Add quadratic invariants\n",
        "    for i in range(input_rep.num_vectors + internal_rep.num_vectors):\n",
        "        for j in range(out_rep.num_vectors):\n",
        "            for r in range(input_rep.num_scalars + internal_rep.num_scalars):\n",
        "                invariants.append(make_quadratic_vector_invariant(i, j, r))\n",
        "\n",
        "    for k in range(input_rep.num_scalars + internal_rep.num_scalars):\n",
        "        for l in range(out_rep.num_scalars):\n",
        "            for r in range(input_rep.num_scalars + internal_rep.num_scalars):\n",
        "              invariants.append(make_quadratic_scalar_invariant(k, l, r))\n",
        "\n",
        "    # Add cubic invariants.  We need to generate differences like <x_p, x_q - x_{q+1}>x_ij\n",
        "\n",
        "    def make_difference(f1, f2):\n",
        "                      def diff(h, m):\n",
        "                          return f1(h, m) - f2(h, m)\n",
        "                      return diff\n",
        "\n",
        "    for i in range(input_rep.num_vectors + internal_rep.num_vectors):\n",
        "        for j in range(out_rep.num_vectors):\n",
        "            for p in range(input_rep.num_vectors + internal_rep.num_vectors):\n",
        "                for q in range(input_rep.num_vectors):\n",
        "                  next_q = (q + 1) % input_rep.num_vectors  # Cyclic index\n",
        "                  f_current = make_cubic_vector_invariant(i, j, p, q)\n",
        "                  f_next = make_cubic_vector_invariant(i, j, p, next_q)\n",
        "\n",
        "                  invariants.append(make_difference(f_current, f_next))\n",
        "\n",
        "                base_q = input_rep.num_vectors\n",
        "                for q_offset in range(internal_rep.num_vectors):\n",
        "                   q = base_q + q_offset\n",
        "                   next_q = base_q + ((q_offset + 1) % internal_rep.num_vectors)\n",
        "                   g_current = make_cubic_vector_invariant(i, j, p, q)\n",
        "                   g_next = make_cubic_vector_invariant(i, j, p, next_q)\n",
        "\n",
        "                   invariants.append(make_difference(g_current, g_next))\n",
        "\n",
        "    for k in range(input_rep.num_scalars + internal_rep.num_scalars):\n",
        "        for l in range(out_rep.num_scalars):\n",
        "          for p in range(input_rep.num_vectors + internal_rep.num_vectors):\n",
        "                for q in range(input_rep.num_vectors):\n",
        "                  next_q = (q + 1) % input_rep.num_vectors  # Cyclic index\n",
        "                  f_current = make_cubic_scalar_invariant(k, l, p, q)\n",
        "                  f_next = make_cubic_scalar_invariant(k, l, p, next_q)\n",
        "\n",
        "                  invariants.append(make_difference(f_current, f_next))\n",
        "\n",
        "                base_q = input_rep.num_vectors\n",
        "                for q_offset in range(internal_rep.num_vectors):\n",
        "                   q = base_q + q_offset\n",
        "                   next_q = base_q + ((q_offset + 1) % internal_rep.num_vectors)\n",
        "                   g_current = make_cubic_scalar_invariant(k, l, p, q)\n",
        "                   g_next = make_cubic_scalar_invariant(k, l, p, next_q)\n",
        "\n",
        "                   invariants.append(make_difference(g_current, g_next))\n",
        "\n",
        "\n",
        "    return invariants"
      ],
      "metadata": {
        "id": "eRRfLPgOkwjz"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we are able to generate invariant functions we can build a model involving several $E(n)$-equivariant layers.  Let's build an $E(3)$-equivariant model with three hidden layers.  The input and output representations will be defined with $W_V = (\\mathbb{R}^4) \\times \\mathbb{R}^{n_f}$, and $W_E = \\mathbb{R}$.  Let's specifically set $n_f = 2$.\n",
        "\n",
        "I'll keep the edge representation trivial in intermediate layers, but allow the vertex representation to vary.  Initially let's say we have the following intermediate layer vertex representations:\n",
        "\\begin{align}\n",
        "W_V^{(2)} &= (\\mathbb R^4)^2 \\times \\mathbb R^2 \\\\\n",
        "W_V^{(3)} &= (\\mathbb R^4)^3 \\times \\mathbb R^3 \\\\\n",
        "W_V^{(4)} &= (\\mathbb R^4)^2 \\times \\mathbb R^2.\n",
        "\\end{align}\n",
        "In each layer I'll set the internal message representation equal to the vertex representation.  I won't use the double layer option for now, and I'll use ReLU activations throughout.\n"
      ],
      "metadata": {
        "id": "FCk-L9QAIVIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 3\n",
        "\n",
        "num_vertices = 4\n",
        "adj_matrix = torch.randint(0,2,(num_vertices, num_vertices))\n",
        "adj_matrix = (adj_matrix + adj_matrix.T) / 2\n",
        "\n",
        "# Define representations\n",
        "input_vertex_rep = EnRepresentation(dim=3, num_vectors=1, num_scalars=2)\n",
        "edge_rep = EnRepresentation(dim=3, num_vectors=0, num_scalars=1)\n",
        "message_rep_1 = input_vertex_rep\n",
        "hidden_vertex_rep_1 = EnRepresentation(dim=3, num_vectors=2, num_scalars=2)\n",
        "hidden_message_rep_1 = hidden_vertex_rep_1\n",
        "hidden_vertex_rep_2 = EnRepresentation(dim=3, num_vectors=3, num_scalars=3)\n",
        "hidden_message_rep_2 = hidden_vertex_rep_2\n",
        "hidden_vertex_rep_3 = EnRepresentation(dim=3, num_vectors=2, num_scalars=2)\n",
        "hidden_message_rep_3 = hidden_vertex_rep_3\n",
        "output_vertex_rep = EnRepresentation(dim=3, num_vectors=1, num_scalars=2)\n",
        "\n",
        "# Layer 1\n",
        "message_invariants_1 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = input_vertex_rep,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = message_rep_1\n",
        ")\n",
        "vertex_invariants_1 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = input_vertex_rep,\n",
        "    internal_rep = message_rep_1,\n",
        "    out_rep = hidden_vertex_rep_1\n",
        ")\n",
        "edge_invariants_1 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = message_rep_1,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer1 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=input_vertex_rep.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=hidden_vertex_rep_1.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=message_rep_1.total_dim(),\n",
        "    inter_invt_funs=message_invariants_1,\n",
        "    vertex_invt_funs=vertex_invariants_1,\n",
        "    edge_invt_funs=edge_invariants_1,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")\n",
        "\n",
        "# Layer 2\n",
        "message_invariants_2 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = hidden_vertex_rep_1,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = hidden_message_rep_1\n",
        ")\n",
        "vertex_invariants_2 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = hidden_vertex_rep_1,\n",
        "    internal_rep = hidden_message_rep_1,\n",
        "    out_rep = hidden_vertex_rep_2\n",
        ")\n",
        "edge_invariants_2 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = hidden_message_rep_1,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer2 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=hidden_vertex_rep_1.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=hidden_vertex_rep_2.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=hidden_message_rep_1.total_dim(),\n",
        "    inter_invt_funs=message_invariants_2,\n",
        "    vertex_invt_funs=vertex_invariants_2,\n",
        "    edge_invt_funs=edge_invariants_2,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")\n",
        "\n",
        "# Layer 3\n",
        "message_invariants_3 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = hidden_vertex_rep_2,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = hidden_message_rep_2\n",
        ")\n",
        "vertex_invariants_3 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = hidden_vertex_rep_2,\n",
        "    internal_rep = hidden_message_rep_2,\n",
        "    out_rep = hidden_vertex_rep_3\n",
        ")\n",
        "edge_invariants_3 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = hidden_message_rep_2,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer3 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=hidden_vertex_rep_2.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=hidden_vertex_rep_3.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=hidden_message_rep_2.total_dim(),\n",
        "    inter_invt_funs=message_invariants_3,\n",
        "    vertex_invt_funs=vertex_invariants_3,\n",
        "    edge_invt_funs=edge_invariants_3,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")\n",
        "\n",
        "# Layer 4\n",
        "message_invariants_4 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = hidden_vertex_rep_3,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = hidden_vertex_rep_3\n",
        ")\n",
        "vertex_invariants_4 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = hidden_vertex_rep_3,\n",
        "    internal_rep = hidden_message_rep_3,\n",
        "    out_rep = output_vertex_rep\n",
        ")\n",
        "edge_invariants_4 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = hidden_message_rep_3,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer4 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=hidden_vertex_rep_3.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=output_vertex_rep.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=hidden_message_rep_3.total_dim(),\n",
        "    inter_invt_funs=message_invariants_4,\n",
        "    vertex_invt_funs=vertex_invariants_4,\n",
        "    edge_invt_funs=edge_invariants_4,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")"
      ],
      "metadata": {
        "id": "jHiJDlleJeXy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnEquivariantNet(nn.Module):\n",
        "\n",
        "    def __init__(self, layers: List[EGCL]):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            layers: List of EGCL layers to be applied in sequence\n",
        "        \"\"\"\n",
        "        super(EnEquivariantNet, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "        # Verify layers are compatible\n",
        "        for i in range(len(layers)-1):\n",
        "            if layers[i].vertex_outputs != layers[i+1].vertex_inputs:\n",
        "                raise ValueError(f\"Layer {i} output dimension {layers[i].vertex_outputs} \"\n",
        "                               f\"doesn't match layer {i+1} input dimension {layers[i+1].vertex_inputs}\")\n",
        "            if layers[i].edge_outputs != layers[i+1].edge_inputs:\n",
        "                raise ValueError(f\"Layer {i} edge output dimension {layers[i].edge_outputs} \"\n",
        "                               f\"doesn't match layer {i+1} edge input dimension {layers[i+1].edge_inputs}\")\n",
        "\n",
        "    def forward(self, h_graph: torch.Tensor, a_graph: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            h_graph: Input vertex features\n",
        "            a_graph: Input edge features\n",
        "\n",
        "        Returns:\n",
        "            tuple(torch.Tensor, torch.Tensor): Final vertex and edge features\n",
        "        \"\"\"\n",
        "        h, a = h_graph, a_graph\n",
        "        for layer in self.layers:\n",
        "            h, a = layer(h, a)\n",
        "        return h, a\n",
        "\n",
        "# Combine layers into model\n",
        "model = EnEquivariantNet([layer1, layer2, layer3, layer4])\n",
        "\n",
        "# Create some example input data\n",
        "h_input = torch.randn(num_vertices, input_vertex_rep.total_dim())\n",
        "a_input = torch.randn(num_vertices, num_vertices, edge_rep.total_dim())\n",
        "\n",
        "# Forward pass through model\n",
        "h_output, a_output = model(h_input, a_input)\n",
        "\n",
        "print(f\"Input vertex features shape: {h_input.shape}\")\n",
        "print(f\"Output vertex features shape: {h_output.shape}\")\n",
        "print(f\"Input edge features shape: {a_input.shape}\")\n",
        "print(f\"Output edge features shape: {a_output.shape}\")"
      ],
      "metadata": {
        "id": "wgFafVIiOwn8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f6e3c4f-8800-49a6-f74b-647d382c7b12"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.0339s, Total: 0.2037s, Count: 6\n",
            "message_sums         - Avg: 0.0004s, Total: 0.0004s, Count: 1\n",
            "vertex_update        - Avg: 0.0488s, Total: 0.1952s, Count: 4\n",
            "edge_update          - Avg: 0.0044s, Total: 0.0266s, Count: 6\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.2313s, Total: 1.3880s, Count: 6\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.2125s, Total: 0.8499s, Count: 4\n",
            "edge_update          - Avg: 0.0081s, Total: 0.0484s, Count: 6\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.7566s, Total: 4.5394s, Count: 6\n",
            "message_sums         - Avg: 0.0010s, Total: 0.0010s, Count: 1\n",
            "vertex_update        - Avg: 0.6163s, Total: 2.4651s, Count: 4\n",
            "edge_update          - Avg: 0.0213s, Total: 0.1275s, Count: 6\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.1489s, Total: 0.8935s, Count: 6\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1032s, Total: 0.4128s, Count: 4\n",
            "edge_update          - Avg: 0.0079s, Total: 0.0473s, Count: 6\n",
            "Input vertex features shape: torch.Size([4, 6])\n",
            "Output vertex features shape: torch.Size([4, 6])\n",
            "Input edge features shape: torch.Size([4, 4, 1])\n",
            "Output edge features shape: torch.Size([4, 4, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now try training the model on the MD17 dataset, using the Benzene molecule and the DFT FHI-aims level of accuracy.  We'll try to learn the atomic force function from the atomic position.  I've reduced the size of layer 3 to $(\\mathbb R^4)^2 \\times \\mathbb R^2$, similarly to the other layers.\n",
        "\n"
      ],
      "metadata": {
        "id": "SszZhWscp2qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install PyTorch Geometric (PyG)\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8VoxU2Cq6m9",
        "outputId": "b5b2f982-6291-48f1-9826-2bbd8ef4cde7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import MD17\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch.optim as optim\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "\n",
        "class MD17Dataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset class for revised MD17 molecular dynamics data (FHI-aims level), specifically for benzene.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        root_dir: str = 'data/md17',\n",
        "        max_samples: int = 1000,\n",
        "        device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir: Directory containing MD17 npz file\n",
        "            max_samples: Maximum number of samples to use\n",
        "            device: Device to store tensors on\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "\n",
        "        # Load benzene data\n",
        "        data  = MD17(root=root_dir, name=\"benzene FHI-aims\")\n",
        "\n",
        "        # Get coordinates and forces\n",
        "        self.coords = torch.stack([d.pos for d in data], dim=0).type(torch.float32).to(self.device)\n",
        "        self.forces = torch.stack([d.force for d in data], dim=0).type(torch.float32).to(self.device)\n",
        "        self.energies = torch.tensor([d.energy.item() for d in data], dtype=torch.float32).to(self.device)  # Extract energy values\n",
        "\n",
        "        # Limit samples\n",
        "        if max_samples and max_samples < len(self.coords):\n",
        "            self.coords = self.coords[:max_samples]\n",
        "            self.forces = self.forces[:max_samples]\n",
        "            self.energies = self.energies[:max_samples]\n",
        "\n",
        "        # Define benzene topology (adjacency matrix)\n",
        "        self.n_atoms = 12  # C6H6\n",
        "        self.adj_matrix = self._create_benzene_adjacency()\n",
        "\n",
        "        # Create atomic features\n",
        "        self.atom_features = self._create_atom_features()\n",
        "\n",
        "    def _create_benzene_adjacency(self) -> torch.Tensor:\n",
        "        \"\"\"Create adjacency matrix for benzene.\"\"\"\n",
        "        adj = torch.zeros((self.n_atoms, self.n_atoms), device=self.device)\n",
        "\n",
        "        # C-C bonds\n",
        "        for i in range(6):\n",
        "            j = (i + 1) % 6\n",
        "            adj[i, j] = adj[j, i] = 1\n",
        "\n",
        "        # C-H bonds\n",
        "        for i in range(6):\n",
        "            adj[i, i+6] = adj[i+6, i] = 1\n",
        "\n",
        "        return adj\n",
        "\n",
        "    def _create_atom_features(self) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Create atomic features using one-hot encoding\n",
        "        \"\"\"\n",
        "        features = torch.zeros((self.n_atoms, 2), device=self.device)\n",
        "        features[:6, 0] = 1  # Carbon atoms\n",
        "        features[6:, 1] = 1  # Hydrogen atoms\n",
        "        return features\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.coords)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Returns:\n",
        "            coords: [n_atoms, 4] homogeneous coordinates\n",
        "            forces: [n_atoms, 4] forces (padded)\n",
        "            edge_features: [n_atoms, n_atoms, 1] edge features (adjacency and distances)\n",
        "        \"\"\"\n",
        "        # Get coordinates and convert to homogeneous coordinates\n",
        "        coords = self.coords[idx]\n",
        "        coords_homog = torch.cat([\n",
        "            coords,\n",
        "            torch.ones((self.n_atoms, 1), device=self.device)\n",
        "        ], dim=1)\n",
        "\n",
        "        # Get forces and pad with zeros\n",
        "        forces = self.forces[idx]\n",
        "        forces_homog = torch.cat([\n",
        "            forces,\n",
        "            torch.zeros((self.n_atoms, 1), device=self.device)\n",
        "        ], dim=1)\n",
        "\n",
        "        # Create edge features as zeroes\n",
        "        edge_features = torch.zeros(\n",
        "        (self.n_atoms, self.n_atoms, 1),\n",
        "        device=self.device\n",
        "    )\n",
        "\n",
        "        return coords_homog, forces_homog, edge_features\n",
        "\n",
        "def create_md17_dataloaders(\n",
        "    root_dir: str,\n",
        "    batch_size: int = 32,\n",
        "    max_samples: int = 1000,\n",
        "    validation_split: float = 0.1,\n",
        "    num_workers: int = 0,\n",
        "    seed: int = 42\n",
        ") -> Tuple[DataLoader, DataLoader]:\n",
        "    \"\"\"Create train and validation dataloaders for MD17 data.\"\"\"\n",
        "\n",
        "    # Create the full dataset\n",
        "    full_dataset = MD17Dataset(root_dir=root_dir)\n",
        "\n",
        "    # Limit the number of samples if specified\n",
        "    if max_samples and max_samples < len(full_dataset):\n",
        "        indices = torch.randperm(len(full_dataset))[:max_samples]\n",
        "        full_dataset = torch.utils.data.Subset(full_dataset, indices)\n",
        "\n",
        "    # Calculate lengths for train/validation split\n",
        "    total_size = len(full_dataset)\n",
        "    val_size = int(validation_split * total_size)\n",
        "    train_size = total_size - val_size\n",
        "\n",
        "    # Create train/validation splits\n",
        "    generator = torch.Generator().manual_seed(seed)\n",
        "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "        full_dataset,\n",
        "        [train_size, val_size],\n",
        "        generator=generator\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=num_workers\n",
        "    )\n",
        "\n",
        "    return train_loader, val_loader"
      ],
      "metadata": {
        "id": "es_c4q0fp6vu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from typing import Tuple, List\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "class ForcePredictor(nn.Module):\n",
        "    def __init__(self, model: EnEquivariantNet):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def forward(self, coords: torch.Tensor, edge_features: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            coords: [batch_size, n_atoms, 4] homogeneous coordinates\n",
        "            edge_features: [batch_size, n_atoms, n_atoms, 1] edge features\n",
        "\n",
        "        Returns:\n",
        "            forces: [batch_size, n_atoms, 4] predicted forces\n",
        "        \"\"\"\n",
        "        print(\"ForcePredictor forward pass starting...\")\n",
        "        batch_size = coords.shape[0]\n",
        "        device = coords.device\n",
        "        n_atoms = coords.shape[1]\n",
        "        print(f\"batch_size: {batch_size}, n_atoms: {n_atoms}\")\n",
        "\n",
        "        # Create one-hot encoding for atom types (C6H6)\n",
        "        atom_features = torch.zeros((n_atoms, 2), device=device)\n",
        "        atom_features[:6, 0] = 1  # Carbon atoms\n",
        "        atom_features[6:, 1] = 1  # Hydrogen atoms\n",
        "        print(\"Created atom features\")\n",
        "\n",
        "        # Process each molecule in batch\n",
        "        all_forces = []\n",
        "        for i in range(batch_size):\n",
        "            print(f\"Processing molecule {i+1}/{batch_size}\")\n",
        "            # Reshape coords[i] to be [n_atoms, 4]\n",
        "            curr_coords = coords[i].reshape(n_atoms, -1)\n",
        "\n",
        "            # Concatenate along the feature dimension\n",
        "            h_graph = torch.cat([\n",
        "                curr_coords,  # [n_atoms, 4]\n",
        "                atom_features # [n_atoms, 2]\n",
        "            ], dim=-1)  # Result: [n_atoms, 6]\n",
        "            print(f\"Created h_graph with shape {h_graph.shape}\")\n",
        "\n",
        "            # Forward pass through model\n",
        "            print(\"Starting model forward pass...\")\n",
        "            h_out, _ = self.model(h_graph, edge_features[i])\n",
        "            print(\"Model forward pass complete\")\n",
        "\n",
        "            # Extract force predictions (first 4 components)\n",
        "            forces = h_out[:, :4]\n",
        "            all_forces.append(forces)\n",
        "            print(f\"Processed molecule {i+1}\")\n",
        "\n",
        "        return torch.stack(all_forces)\n",
        "\n",
        "def train_epoch(\n",
        "    model: ForcePredictor,\n",
        "    train_loader: DataLoader,\n",
        "    optimizer: optim.Optimizer,\n",
        "    criterion: nn.Module,\n",
        "    device: str\n",
        ") -> float:\n",
        "    \"\"\"Train for one epoch.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for coords, forces, edge_features in train_loader:\n",
        "        coords = coords.to(device)\n",
        "        forces = forces.to(device)\n",
        "        edge_features = edge_features.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        pred_forces = model(coords,  edge_features)\n",
        "\n",
        "        # Compute loss only on spatial components\n",
        "        loss = criterion(pred_forces[..., :3], forces[..., :3])\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(train_loader)\n",
        "\n",
        "def validate(\n",
        "    model: ForcePredictor,\n",
        "    val_loader: DataLoader,\n",
        "    criterion: nn.Module,\n",
        "    device: str\n",
        ") -> float:\n",
        "    \"\"\"Compute validation loss.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for coords, forces, edge_features in val_loader:\n",
        "            coords = coords.to(device)\n",
        "            forces = forces.to(device)\n",
        "            edge_features = edge_features.to(device)\n",
        "\n",
        "            pred_forces = model(coords, edge_features)\n",
        "            loss = criterion(pred_forces[..., :3], forces[..., :3])\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(val_loader)\n",
        "\n",
        "def train_model(\n",
        "    model: ForcePredictor,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    n_epochs: int = 100,\n",
        "    learning_rate: float = 1e-3,\n",
        "    device: str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        ") -> Tuple[List[float], List[float]]:\n",
        "    \"\"\"Train model and return training history.\"\"\"\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        train_batches = 0\n",
        "\n",
        "        train_pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{n_epochs} [Train]')\n",
        "        for coords, forces, edge_features in train_pbar:\n",
        "            # Move to device\n",
        "            coords = coords.to(device)\n",
        "            forces = forces.to(device)\n",
        "            edge_features = edge_features.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass with memory tracking\n",
        "            with torch.cuda.amp.autocast(enabled=True):  # Mixed precision\n",
        "                pred_forces = model(coords, edge_features)\n",
        "                loss = criterion(pred_forces[..., :3], forces[..., :3])\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Log loss\n",
        "            total_train_loss += loss.item()\n",
        "            train_batches += 1\n",
        "            train_pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
        "\n",
        "            # Clear memory\n",
        "            del pred_forces, loss\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        avg_train_loss = total_train_loss / train_batches\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        val_batches = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_pbar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{n_epochs} [Val]')\n",
        "            for coords, forces, edge_features in val_pbar:\n",
        "                coords = coords.to(device)\n",
        "                forces = forces.to(device)\n",
        "                edge_features = edge_features.to(device)\n",
        "\n",
        "                with torch.amp.autocast(enabled=True):\n",
        "                    pred_forces = model(coords, edge_features)\n",
        "                    loss = criterion(pred_forces[..., :3], forces[..., :3])\n",
        "\n",
        "                total_val_loss += loss.item()\n",
        "                val_batches += 1\n",
        "                val_pbar.set_postfix({'loss': f'{loss.item():.6f}'})\n",
        "\n",
        "                # Clear memory\n",
        "                del pred_forces, loss\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        avg_val_loss = total_val_loss / val_batches\n",
        "        val_losses.append(avg_val_loss)\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{n_epochs} Summary:\")\n",
        "        print(f\"Train Loss: {avg_train_loss:.6f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.6f}\")\n",
        "        print(f\"Time: {epoch_time:.2f}s\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "    return train_losses, val_losses\n",
        "\n"
      ],
      "metadata": {
        "id": "zl3GzY-2cs8n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader = create_md17_dataloaders(\n",
        "    root_dir='data/md17',\n",
        "    batch_size=2,\n",
        "    max_samples=1000\n",
        ")"
      ],
      "metadata": {
        "id": "2ZnBYGtrLzly"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dim = 3\n",
        "\n",
        "num_vertices = 12\n",
        "\n",
        "adj_matrix = torch.zeros((num_vertices, num_vertices), device='cuda')\n",
        "\n",
        "# C-C bonds\n",
        "for i in range(6):\n",
        "    j = (i + 1) % 6\n",
        "    adj_matrix[i, j] = adj_matrix[j, i] = 1\n",
        "\n",
        "# C-H bonds\n",
        "for i in range(6):\n",
        "    adj_matrix[i, i+6] = adj_matrix[i+6, i] = 1\n",
        "\n",
        "# Define representations\n",
        "input_vertex_rep = EnRepresentation(dim=3, num_vectors=1, num_scalars=2)\n",
        "edge_rep = EnRepresentation(dim=3, num_vectors=0, num_scalars=1)\n",
        "message_rep_1 = input_vertex_rep\n",
        "hidden_vertex_rep_1 = EnRepresentation(dim=3, num_vectors=2, num_scalars=2)\n",
        "hidden_message_rep_1 = hidden_vertex_rep_1\n",
        "hidden_vertex_rep_2 = EnRepresentation(dim=3, num_vectors=2, num_scalars=2)\n",
        "hidden_message_rep_2 = hidden_vertex_rep_2\n",
        "hidden_vertex_rep_3 = EnRepresentation(dim=3, num_vectors=2, num_scalars=2)\n",
        "hidden_message_rep_3 = hidden_vertex_rep_3\n",
        "output_vertex_rep = EnRepresentation(dim=3, num_vectors=1, num_scalars=2)\n",
        "\n",
        "# Layer 1\n",
        "message_invariants_1 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = input_vertex_rep,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = message_rep_1\n",
        ")\n",
        "vertex_invariants_1 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = input_vertex_rep,\n",
        "    internal_rep = message_rep_1,\n",
        "    out_rep = hidden_vertex_rep_1\n",
        ")\n",
        "edge_invariants_1 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = message_rep_1,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer1 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=input_vertex_rep.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=hidden_vertex_rep_1.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=message_rep_1.total_dim(),\n",
        "    inter_invt_funs=message_invariants_1,\n",
        "    vertex_invt_funs=vertex_invariants_1,\n",
        "    edge_invt_funs=edge_invariants_1,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")\n",
        "\n",
        "# Layer 2\n",
        "message_invariants_2 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = hidden_vertex_rep_1,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = hidden_message_rep_1\n",
        ")\n",
        "vertex_invariants_2 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = hidden_vertex_rep_1,\n",
        "    internal_rep = hidden_message_rep_1,\n",
        "    out_rep = hidden_vertex_rep_2\n",
        ")\n",
        "edge_invariants_2 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = hidden_message_rep_1,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer2 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=hidden_vertex_rep_1.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=hidden_vertex_rep_2.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=hidden_message_rep_1.total_dim(),\n",
        "    inter_invt_funs=message_invariants_2,\n",
        "    vertex_invt_funs=vertex_invariants_2,\n",
        "    edge_invt_funs=edge_invariants_2,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")\n",
        "\n",
        "# Layer 3\n",
        "message_invariants_3 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = hidden_vertex_rep_2,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = hidden_message_rep_2\n",
        ")\n",
        "vertex_invariants_3 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = hidden_vertex_rep_2,\n",
        "    internal_rep = hidden_message_rep_2,\n",
        "    out_rep = hidden_vertex_rep_3\n",
        ")\n",
        "edge_invariants_3 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = hidden_message_rep_2,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer3 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=hidden_vertex_rep_2.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=hidden_vertex_rep_3.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=hidden_message_rep_2.total_dim(),\n",
        "    inter_invt_funs=message_invariants_3,\n",
        "    vertex_invt_funs=vertex_invariants_3,\n",
        "    edge_invt_funs=edge_invariants_3,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")\n",
        "\n",
        "# Layer 4\n",
        "message_invariants_4 = generate_En_message_invariants(\n",
        "    dim = dim,\n",
        "    vertex_rep = hidden_vertex_rep_3,\n",
        "    edge_rep = edge_rep,\n",
        "    out_rep = hidden_vertex_rep_3\n",
        ")\n",
        "vertex_invariants_4 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = hidden_vertex_rep_3,\n",
        "    internal_rep = hidden_message_rep_3,\n",
        "    out_rep = output_vertex_rep\n",
        ")\n",
        "edge_invariants_4 = generate_En_vertex_edge_invariants(\n",
        "    dim = dim,\n",
        "    input_rep = edge_rep,\n",
        "    internal_rep = hidden_message_rep_3,\n",
        "    out_rep = edge_rep\n",
        ")\n",
        "\n",
        "layer4 = EGCL(\n",
        "    num_vertices = num_vertices,\n",
        "    adj_matrix = adj_matrix,\n",
        "    vertex_inputs=hidden_vertex_rep_3.total_dim(),\n",
        "    edge_inputs=edge_rep.total_dim(),\n",
        "    vertex_outputs=output_vertex_rep.total_dim(),\n",
        "    edge_outputs=edge_rep.total_dim(),\n",
        "    inter_vars=hidden_message_rep_3.total_dim(),\n",
        "    inter_invt_funs=message_invariants_4,\n",
        "    vertex_invt_funs=vertex_invariants_4,\n",
        "    edge_invt_funs=edge_invariants_4,\n",
        "    inter_activation=torch.nn.ReLU(),\n",
        "    vertex_activation=torch.nn.ReLU(),\n",
        "    edge_activation=torch.nn.ReLU(),\n",
        "    is_affine=True\n",
        ")"
      ],
      "metadata": {
        "id": "_b8nA5JSjhcY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EnEquivariantNet(nn.Module):\n",
        "\n",
        "    def __init__(self, layers: List[EGCL]):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            layers: List of EGCL layers to be applied in sequence\n",
        "        \"\"\"\n",
        "        super(EnEquivariantNet, self).__init__()\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "        # Verify layers are compatible\n",
        "        for i in range(len(layers)-1):\n",
        "            if layers[i].vertex_outputs != layers[i+1].vertex_inputs:\n",
        "                raise ValueError(f\"Layer {i} output dimension {layers[i].vertex_outputs} \"\n",
        "                               f\"doesn't match layer {i+1} input dimension {layers[i+1].vertex_inputs}\")\n",
        "            if layers[i].edge_outputs != layers[i+1].edge_inputs:\n",
        "                raise ValueError(f\"Layer {i} edge output dimension {layers[i].edge_outputs} \"\n",
        "                               f\"doesn't match layer {i+1} edge input dimension {layers[i+1].edge_inputs}\")\n",
        "\n",
        "    def forward(self, h_graph: torch.Tensor, a_graph: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            h_graph: Input vertex features\n",
        "            a_graph: Input edge features\n",
        "\n",
        "        Returns:\n",
        "            tuple(torch.Tensor, torch.Tensor): Final vertex and edge features\n",
        "        \"\"\"\n",
        "        h, a = h_graph, a_graph\n",
        "        for layer in self.layers:\n",
        "            h, a = layer(h, a)\n",
        "        return h, a\n",
        "\n",
        "# Combine layers into model\n",
        "BenzeneEquivariantNet = EnEquivariantNet([layer1, layer2, layer3, layer4])\n",
        "\n",
        "# Create some example input data\n",
        "h_input = torch.randn(num_vertices, input_vertex_rep.total_dim())\n",
        "a_input = torch.randn(num_vertices, num_vertices, edge_rep.total_dim())\n",
        "\n",
        "# Forward pass through model\n",
        "h_output, a_output = BenzeneEquivariantNet(h_input, a_input)\n",
        "\n",
        "print(f\"Input vertex features shape: {h_input.shape}\")\n",
        "print(f\"Output vertex features shape: {h_output.shape}\")\n",
        "print(f\"Input edge features shape: {a_input.shape}\")\n",
        "print(f\"Output edge features shape: {a_output.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgVlfHEBjmbq",
        "outputId": "2b3de6da-3a29-4731-ab2e-525ffabcd9c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.0247s, Total: 0.2963s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0341s, Total: 0.4090s, Count: 12\n",
            "edge_update          - Avg: 0.0032s, Total: 0.0384s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1428s, Total: 1.7131s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1382s, Total: 1.6583s, Count: 12\n",
            "edge_update          - Avg: 0.0086s, Total: 0.1033s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1904s, Total: 2.2846s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1397s, Total: 1.6766s, Count: 12\n",
            "edge_update          - Avg: 0.0079s, Total: 0.0946s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1481s, Total: 1.7767s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1067s, Total: 1.2802s, Count: 12\n",
            "edge_update          - Avg: 0.0079s, Total: 0.0951s, Count: 12\n",
            "Input vertex features shape: torch.Size([12, 6])\n",
            "Output vertex features shape: torch.Size([12, 6])\n",
            "Input edge features shape: torch.Size([12, 12, 1])\n",
            "Output edge features shape: torch.Size([12, 12, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ForcePredictor(BenzeneEquivariantNet)\n",
        "train_losses, val_losses = train_model(model, train_loader, val_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di1pNwNBj7j6",
        "outputId": "6897c45d-4254-4607-db79-09dfa7b56848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/100 [Train]:   0%|          | 0/450 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForcePredictor forward pass starting...\n",
            "batch_size: 2, n_atoms: 12\n",
            "Created atom features\n",
            "Processing molecule 1/2\n",
            "Created h_graph with shape torch.Size([12, 6])\n",
            "Starting model forward pass...\n",
            "EGCL forward pass starting...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-668250992770>:144: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=True):  # Mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.0725s, Total: 0.8700s, Count: 12\n",
            "message_sums         - Avg: 0.0002s, Total: 0.0002s, Count: 1\n",
            "vertex_update        - Avg: 0.0818s, Total: 0.9817s, Count: 12\n",
            "edge_update          - Avg: 0.0061s, Total: 0.0728s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.1671s, Total: 2.0054s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1292s, Total: 1.5509s, Count: 12\n",
            "edge_update          - Avg: 0.0076s, Total: 0.0907s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1393s, Total: 1.6719s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1506s, Total: 1.8069s, Count: 12\n",
            "edge_update          - Avg: 0.0073s, Total: 0.0877s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.1766s, Total: 2.1197s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1040s, Total: 1.2484s, Count: 12\n",
            "edge_update          - Avg: 0.0078s, Total: 0.0939s, Count: 12\n",
            "Model forward pass complete\n",
            "Processed molecule 1\n",
            "Processing molecule 2/2\n",
            "Created h_graph with shape torch.Size([12, 6])\n",
            "Starting model forward pass...\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.0231s, Total: 0.2776s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0318s, Total: 0.3820s, Count: 12\n",
            "edge_update          - Avg: 0.0035s, Total: 0.0416s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1507s, Total: 1.8086s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1390s, Total: 1.6678s, Count: 12\n",
            "edge_update          - Avg: 0.0080s, Total: 0.0955s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.2056s, Total: 2.4674s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.2393s, Total: 2.8714s, Count: 12\n",
            "edge_update          - Avg: 0.0079s, Total: 0.0953s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1526s, Total: 1.8315s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.2112s, Total: 2.5349s, Count: 12\n",
            "edge_update          - Avg: 0.0078s, Total: 0.0941s, Count: 12\n",
            "Model forward pass complete\n",
            "Processed molecule 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   0%|          | 1/450 [01:29<11:11:36, 89.75s/it, loss=1566.694702]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForcePredictor forward pass starting...\n",
            "batch_size: 2, n_atoms: 12\n",
            "Created atom features\n",
            "Processing molecule 1/2\n",
            "Created h_graph with shape torch.Size([12, 6])\n",
            "Starting model forward pass...\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.0242s, Total: 0.2904s, Count: 12\n",
            "message_sums         - Avg: 0.0002s, Total: 0.0002s, Count: 1\n",
            "vertex_update        - Avg: 0.0308s, Total: 0.3696s, Count: 12\n",
            "edge_update          - Avg: 0.0033s, Total: 0.0398s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1717s, Total: 2.0609s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1552s, Total: 1.8618s, Count: 12\n",
            "edge_update          - Avg: 0.0075s, Total: 0.0902s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1407s, Total: 1.6879s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1292s, Total: 1.5504s, Count: 12\n",
            "edge_update          - Avg: 0.0071s, Total: 0.0850s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1407s, Total: 1.6882s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1388s, Total: 1.6656s, Count: 12\n",
            "edge_update          - Avg: 0.0112s, Total: 0.1347s, Count: 12\n",
            "Model forward pass complete\n",
            "Processed molecule 1\n",
            "Processing molecule 2/2\n",
            "Created h_graph with shape torch.Size([12, 6])\n",
            "Starting model forward pass...\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.0343s, Total: 0.4116s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0297s, Total: 0.3564s, Count: 12\n",
            "edge_update          - Avg: 0.0036s, Total: 0.0431s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1645s, Total: 1.9742s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1320s, Total: 1.5842s, Count: 12\n",
            "edge_update          - Avg: 0.0074s, Total: 0.0883s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1388s, Total: 1.6659s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1535s, Total: 1.8422s, Count: 12\n",
            "edge_update          - Avg: 0.0092s, Total: 0.1098s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1615s, Total: 1.9375s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1307s, Total: 1.5686s, Count: 12\n",
            "edge_update          - Avg: 0.0084s, Total: 0.1014s, Count: 12\n",
            "Model forward pass complete\n",
            "Processed molecule 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/100 [Train]:   0%|          | 2/450 [02:52<10:38:47, 85.55s/it, loss=499.160980]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ForcePredictor forward pass starting...\n",
            "batch_size: 2, n_atoms: 12\n",
            "Created atom features\n",
            "Processing molecule 1/2\n",
            "Created h_graph with shape torch.Size([12, 6])\n",
            "Starting model forward pass...\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.0257s, Total: 0.3089s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0328s, Total: 0.3939s, Count: 12\n",
            "edge_update          - Avg: 0.0034s, Total: 0.0403s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.2277s, Total: 2.7329s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1323s, Total: 1.5870s, Count: 12\n",
            "edge_update          - Avg: 0.0073s, Total: 0.0879s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1708s, Total: 2.0492s, Count: 12\n",
            "message_sums         - Avg: 0.0002s, Total: 0.0002s, Count: 1\n",
            "vertex_update        - Avg: 0.1450s, Total: 1.7396s, Count: 12\n",
            "edge_update          - Avg: 0.0071s, Total: 0.0848s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1420s, Total: 1.7041s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0964s, Total: 1.1570s, Count: 12\n",
            "edge_update          - Avg: 0.0073s, Total: 0.0874s, Count: 12\n",
            "Model forward pass complete\n",
            "Processed molecule 1\n",
            "Processing molecule 2/2\n",
            "Created h_graph with shape torch.Size([12, 6])\n",
            "Starting model forward pass...\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.0238s, Total: 0.2859s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.0313s, Total: 0.3758s, Count: 12\n",
            "edge_update          - Avg: 0.0033s, Total: 0.0394s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.1879s, Total: 2.2549s, Count: 12\n",
            "message_sums         - Avg: 0.0002s, Total: 0.0002s, Count: 1\n",
            "vertex_update        - Avg: 0.2396s, Total: 2.8747s, Count: 12\n",
            "edge_update          - Avg: 0.0354s, Total: 0.4248s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "intermediate_term    - Avg: 0.1723s, Total: 2.0680s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.2251s, Total: 2.7012s, Count: 12\n",
            "edge_update          - Avg: 0.0072s, Total: 0.0867s, Count: 12\n",
            "EGCL forward pass starting...\n",
            "\n",
            "EGCL Layer Timing Summary:\n",
            "init_messages        - Avg: 0.0000s, Total: 0.0000s, Count: 1\n",
            "intermediate_term    - Avg: 0.1698s, Total: 2.0378s, Count: 12\n",
            "message_sums         - Avg: 0.0001s, Total: 0.0001s, Count: 1\n",
            "vertex_update        - Avg: 0.1425s, Total: 1.7097s, Count: 12\n",
            "edge_update          - Avg: 0.0078s, Total: 0.0930s, Count: 12\n",
            "Model forward pass complete\n",
            "Processed molecule 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I've noticed that the EGCL forward pass is running very slowly, and I've added some timing to try to see why.  Specifically it's the intermediate_term and vertex_update steps (that compute a linear combination of the invariant functions) that are taking such a long time to run for each vertex.  Right now I'm not able to proceed until I can figure out a way of speeding them up."
      ],
      "metadata": {
        "id": "aVqhcQbt0VO8"
      }
    }
  ]
}